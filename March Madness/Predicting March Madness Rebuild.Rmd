---
title: "Predicting March Madness"
author: "Ken Harmon"
date: "`r format(Sys.time(), '%Y %B %d')`"
output:
  html_document:  
    keep_md: true
    code_folding: hide
    fig_height: 6
    fig_width: 12
    fig_align: 'center'
editor_options: 
  chunk_output_type: console
---

# {.tabset .tabset-fade}

```{r, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```






```{r load_libraries, include=FALSE}
# Use this R-Chunk to load all your libraries!
#install.packages("tidyverse") # run this line once in console to get package

pacman::p_load(tidyverse, rpart, rpart.plot, factoextra, MASS, ROCR, neuralnet, Metrics, caret, DT)

theme_set(theme_bw())
```

## The MMdata

NCAA Season Stats: https://www.sports-reference.com/cbb/seasons/

All Tournament Game Results:

  From which I can get Seed Expectations
  From Which I can get each teams PASE
  
Kenpom Rankings: https://kenpom.com/index.php?s=TeamName

### 2002 to 2019 Games

```{r DT}
# Load MMdata of all games and the differences of season stats
read.csv( "AGwDS.csv", stringsAsFactor = FALSE ) -> AGwDS

MMdata <- AGwDS[,22:58] %>% mutate(result = D.Score) %>% transform(result = ifelse (result > 0 ,1,0))%>% dplyr::select(-c(4,19)) %>% na.omit()

#MMdata <-MMdata%>%dplyr::select(c(1,8,9,16:19,21,22,24,25,27:36))

#check for na

#apply(is.na(MMdata),2,which)

datatable(MMdata, extensions = "Responsive",options=list(lengthMenu = c(10,25,68)))
```

```{r std}
# Spliting training and testing MMdata
index = sample( 1:nrow(MMdata), nrow(MMdata) * 0.8, replace = FALSE ) 

trainset = MMdata[index,]
test = MMdata[-index,]
testset = test[1:ncol(test)-1]  # all variables without the class
```

## Neural Net

```{r nn}
# Building a neural network (NN)

n = names( trainset )
f = as.formula( paste( "result ~", paste( n[!n %in% "result"], collapse = "+" ) ) )
nn = neuralnet( f, trainset, hidden = 6, linear.output = FALSE, threshold = 0.01 )

plot( nn, rep = "best" )
```

```{r nncm}
# Testing the result output
nn.results = compute( nn, testset )

results = data.frame( actual = test$result, prediction = round( nn.results$net.result ) )

# Confusion matrix

t = table( results )
print( confusionMatrix( t ) )
```

## Principle Components

```{r pctt}
pca_trainset = trainset[1:ncol(trainset)-1]  # all variables without the class
pca_testset = testset
pca = prcomp( pca_trainset, center = F, scale. = F )

# variance
pr_var = ( pca$sdev )^2 

# % of variance
prop_varex = pr_var / sum( pr_var )

# Plot
plot( prop_varex, xlab = "Principal Component", 
                  ylab = "Proportion of Variance Explained", type = "b" )
```

```{r sp}
# Scree Plot
plot( cumsum( prop_varex ), xlab = "Principal Component", 
                            ylab = "Cumulative Proportion of Variance Explained", type = "b" )
```

```{r nnnpd}
# Creating a new MMdata
train = data.frame( result = trainset$result, pca$x )
t = as.data.frame( predict( pca, newdata = pca_testset ) )

PCs <- 5
new_trainset = train[, 1:(PCs+1)] # class on front and PCs to use
new_testset =  t[, 1:PCs] # Just PCs to use

# Build the neural network (NN)

n = names( new_trainset )
f = as.formula( paste( "result ~", paste( n[!n %in% "result" ], collapse = "+" ) ) )
nn = neuralnet( f, new_trainset, hidden = 3, linear.output = FALSE, threshold=0.01 )

# Plot the NN
plot( nn, rep = "best" )
```

```{r nnncm}
# Test the resulting output
nn.results = compute( nn, new_testset )

# Results
results = data.frame( actual = test$result, 
                      prediction = round( nn.results$net.result ) )

# Confusion Matrix

t = table( results ) 
print( confusionMatrix( t ) )
```

## Recursive Partitioning

```{r rptt}
set.seed(1)

# Shuffle the dataset; build train and test
n <- nrow(MMdata)
shuffled <- MMdata[sample(n),]
train <- shuffled[1:round(0.8 * n),]
test <- shuffled[(round(0.8 * n) + 1):n,]

# Fill in the model that has been learned.
tree <- rpart(result ~ ., train, method = "class")
prp(tree, type =3)
```

```{r rpcm}
# Predict the outcome on the test set with tree: pred
pred <- predict(tree, test, type = "class")

# Results
results = data.frame(test$result, pred)

# Confusion Matrix

t = table( results ) 
print( confusionMatrix( t ) )
```

## GLM

```{r glmm}
# Fit glm model: model
model <- glm(result ~ ., family = "binomial", train)

# Predict on test: p
p <- predict(model, test, type = "response")
```

```{r glmcm}
# If p exceeds threshold of 0.5, M else R: m_or_r
foru <- ifelse(p > .5, 1, 0)

# Create confusion matrix
results = data.frame(test$result, foru)
t = table( results ) 
confusionMatrix(t)
```

